<!--
Dependecies:
jQuery JavaScript Library v1.4.2
http://jquery.com/
Copyright 2010, John Resig
Dual licensed under the MIT or GPL Version 2 licenses.
http://jquery.org/license
-----------------------------------------------------
Bootstrap
Copyright (c) 2011-2019 Twitter, Inc.
Copyright (c) 2011-2019 The Bootstrap Authors
https://github.com/twbs/bootstrap/blob/v4.3.1/LICENSE
-----------------------------------------------------
Vanta
https://github.com/tengbao/vanta
-----------------------------------------------------
Author: Joshua Cao | yuchenca@andrew.cmu.edu
Webiste: 16726 course website
-->
<!doctype html>
<html>

<head>
    <!-- icon -->
    <link rel="icon" href="./media/joshua.ico" type="image/x-icon">
    <link rel="shortcut icon" href="./media/joshua.ico" type="image/x-icon">
    <link rel="bookmark" href="./media/joshua.ico" type="image/x-icon">
    <!-- title -->
    <title>16726-Yuchenca</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <meta name="description" content="16726-Yuchenca">
    <meta name="keywords" lang="de" content="16726-Yuchenca">
    <!-- jQuery -->
    <script type="text/javascript" src="./js/jQuery-3.3.1.js"></script>
    <!-- Bootstrap -->
    <link type="text/css" href="./css/bootstrap.min.css" rel='stylesheet'>
    <script type="text/javascript" src="./js/bootstrap.min.js"></script>
    <!-- main -->
    <link type="text/css" href="./css/main.css" rel='stylesheet'>
    <script type="text/javascript" src="./js/main.js"></script>
    <!-- vanta -->
    <script type="text/javascript" src="./js/three.min.js"></script>
    <script type="text/javascript" src="./js/ring.min.js"></script>
    <script type="text/javascript" src="./js/cloud.min.js"></script>
</head>

<body>
    <div style="width:100%;height:100%">
        <!-- title -->
        <div  id="cloud">
            <div class="row">
                <div class="col-12 mx-12">
                    <div id="title" class="text-center">
                        <span id="title-top" class="font-weight-bold">16726 Learning-based Image Synthesis Spring 22</span>
                        <br>
                        <span id="title-bot">Joshua Cao | Carnegie Mellon University</span>
                    </div>
                </div>
            </div>
            <br><br>
            <!-- navigation -->
            <ul id="navigation" class="nav nav-tabs font-weight-bold text-center" role="tablist">
                <li class="nav-item">
                    <a class="nav-link" id="home-tab" data-toggle="tab" href="#home" role="tab" aria-controls="home" aria-selected="false">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="a1-tab" data-toggle="tab" href="#a1" role="tab" aria-controls="a1" aria-selected="false">Assignment1</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" id="a2-tab" data-toggle="tab" href="#a2" role="tab" aria-controls="a2" aria-selected="true">Assignment2</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="a3-tab" data-toggle="tab" href="#a3" role="tab" aria-controls="a3" aria-selected="false">Assignment3</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="a4-tab" data-toggle="tab" href="#a4" role="tab" aria-controls="a4" aria-selected="false">Assignment4</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" id="a5-tab" data-toggle="tab" href="#a5" role="tab" aria-controls="a5" aria-selected="false">Assignment5</a>
                </li>
            </ul>
        </div>
        <div class="tab-content container" id="TabContent">
            <div class="tab-pane fade" id="home" role="tabpanel" aria-labelledby="home-tab">
                <div class="row">
                    <div class="col-12 my-5 mx-3">
                        <h2>About Course</h2>
                        <hr class="col-xs-12 mr-4">
                        <p class="col-xs-12 mr-4">
                            <a class="underline" href="https://learning-image-synthesis.github.io/sp22/" target="_blank">16-726 Learning-Based Image Synthesis / Spring 2022</a> is led by <a class="underline" href="https://www.cs.cmu.edu/~junyanz/" target="_blank">Professor Jun-yan Zhu</a>, and assisted by TAs <a class="underline" href="https://peterwang512.github.io/" target="_blank">Sheng-Yu Wang</a> and <a class="underline" href="https://linzhiqiu.github.io/" target="_blank">Zhi-Qiu Lin</a>.
                        </p>
                        <p class="col-xs-12 mr-4">
                            This course introduces machine learning methods for image and video synthesis. The objectives of synthesis research vary from modeling statistical distributions of visual data, through realistic picture-perfect recreations of the world in graphics, and all the way to providing interactive tools for artistic expression. Key machine learning algorithms will be presented, ranging from classical learning methods (e.g., nearest neighbor, PCA, Markov Random Fields) to deep learning models (e.g., ConvNets, deep generative models, such as GANs and VAEs). We will also introduce image and video forensics methods for detecting synthetic content. In this class, students will learn to build practical applications and create new visual effects using their own photos and videos.
                        </p>
                        <h2>Assigment Summary</h2>
                        <hr class="col-xs-12 mr-4">
                        <div class="row mx-1">
                            <div class="col-12">
                                <p class="col-xs-12">
                                    <table class="table">
                                        <thead>
                                            <tr>
                                                <th scope="col"></th>
                                                <th scope="col">Topic</th>
                                                <th scope="col">Abstract</th>
                                                <th scope="col">Reference</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <th scope="row">A1</th>
                                                <td>Colorizing the Prokudin-Gorskii Photo Collection</td>
                                                <td>Implement SSD, pyramid structure, USM, auto crop, contrast methods </td>
                                                <td>
                                                    <a class="underline" href="http://lcweb2.loc.gov/master/pnp/prok/" target="_blank">Dataset</a><br>
                                                    <a class="underline" href="https://en.wikipedia.org/wiki/Unsharp_masking" target="_blank">USM</a><br>
                                                    <a class="underline" href="https://en.wikipedia.org/wiki/Hough_transform" target="_blank">Hough Transform</a><br>
                                                </td>
                                            </tr>
                                            <tr>
                                                <th scope="row">A2</th>
                                                <td>Gradient Domain Fusion</td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                            <tr>
                                                <th scope="row">A3</th>
                                                <td>When Cats meet GANs</td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                            <tr>
                                                <th scope="row">A4</th>
                                                <td>Neural Style Transfer</td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                            <tr>
                                                <th scope="row">A5</th>
                                                <td>GAN Photo Editing</td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </p>
                            </div>
                        </div>
                        <h2>Copyright</h2>
                        <hr class="col-xs-12 mr-4">
                        <p class="col-xs-12 mr-4">
                            <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a> All datasets, teaching resources and training networks on this page are copyright by Carnegie Mellon University and published under the <a class="underline" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. This means that you must attribute the work in the manner specified by the authors, you may not use this work for commercial purposes and if you alter, transform, or build upon this work, you may distribute the resulting work only under the same license.
                        </p>
                    </div>
                </div>
            </div>
            <div class="tab-pane fade" id="a1" role="tabpanel" aria-labelledby="a1-tab">
                <div class="row">
                    <div class="col-12 my-5 mx-3">
                        <h2>Assignment #1</h2>
                        <hr class="col-xs-12 mr-4">
                        <h3>Introduction</h3>
                        <p class="col-xs-12 mr-4">
                            The Prokudin-Gorskii image collection from the Library of Congress is a series of glass plate negative photographs taken by Sergei Mikhailovich Prokudin-Gorskii. To view these photographs in color digitally, one must overlay the three images and display them in their respective RGB channels. However, due to the technology used to take these images, the three photos are not perfectly aligned. The goal of this project is to automatically align, clean up, and display a single color photograph from a glass plate negative.
                        </p>
                        <hr class="col-xs-12 mr-4">
                        <h3>Direct Method</h3>
                        <p class="col-xs-12 mr-4">
                            Before diving into algorithms, I decide to blend R, G, B images directly and have an intuitive feeling of the tasks, which at the same time provides a reference to compare how far my algorithm can go. There are total 1 small jpeg and 9 large tiff images from the given dataset. Their direct blending goes as below:
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/direct/cathedral.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/emir.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/harvesters.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/icon.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/lady.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/self_portrait.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/three_generations.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/train.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/turkmen.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/direct/village.jpg" height="180px" alt="image_left">
                            </div>
                        </div>
                        <hr class="col-xs-12 mr-4">
                        <h3>SSD & NCC Alignment</h3>
                        <p class="col-xs-12 mr-4">
                            I implement both SSD and NCC to compare the small patch's similarity for alignment, the search range is [-15,15], and the algorithm works both well on the small jpeg image as shown below. To speed up the calculation, I also cropped 20% of each side of the image to decrease calculation on the edge. However, to deal with larger image, not only the search range is not large enough, but also the calulation takes extremely long. Therefore, the pyramid structure comes to practice.
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/pyramid/cathedral.jpg" height="280px" alt="image_left">
                            </div>
                        </div>
                        <hr class="col-xs-12 mr-4">
                        <h3>Pyramid Aligment</h3>
                        <p class="col-xs-12 mr-4">
                            I use log2(min(image.shape)) to find out how many mamixmum layers the image can have, and add conditions to only apply the pyramid algorithm for images larger than 512*512, and the small image can directly use [-15,15] SSD search. For large images, my starting layer is a size around 265 pixels(2^8 as first layer), and exhaustively search till the original image size, because I realized missing final layer will give me color bias all the time(misalignment of color channel is very easy to detect even though it's just small pixels). The first implementation of my method took 180s for one image. To speed it up, I recursively decrease search region by 2 each time to shorten it to 55 seconds per iamge, because the center of search box is determined by last layer, so the deeper algorithm search, the smaller search range it requires to find the best alignment. The output is listed as below. As you can see, most of the images are aligned quite well but image like the piece of Sergei Mikhailovich Prokudin-Gorskii, work even worse than direct alignment, this is because the brightness of the images are different, therefore, I use an USM(Unsharp Mask) algorithm to fix the issue.
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/pyramid/cathedral.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/emir.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/harvesters.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/icon.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/lady.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/self_portrait.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/three_generations.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/train.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/turkmen.jpg" height="180px" alt="image_left">
                                <img src="./media/a1/pyramid/village.jpg" height="180px" alt="image_left">
                            </div>
                        </div>
                        <hr class="col-xs-12 mr-4">
                        <h2>Extra Credits</h2>
                        <h3>USM Unsharp Mask</h3>
                        <p class="col-xs-12 mr-4">
                            The USM algorithm is mainly to sharpen or soften the edge of images, and allows accurate SSD difference to make better alignment. The algorithm is called for each recursion in the pyramid alignment, and it first uses Gaussian Blur to blur the single channel(gray) image, and subtract it from the original image, then I take the region of difference that is larger than certain threshold and subtract them from the original image and multiple certain constant parameters. Here I use subraction because I notice certain edge needs to be softened instead of being sharpened, due to some disturbing edges stand out too much in the original image that makes SSD find the wrong alignment. The USM specifically improves the quality of this image:
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/usm/emir.jpg" height="280px" alt="image_left">
                            </div>
                        </div>
                        <hr class="col-xs-12 mr-4">
                        <h3>Crop Image</h3>
                        <p class="col-xs-12 mr-4">
                            To get rid of the borders, I mainly use two cropping method, the first one is to keep area only for all three channels have contents, and remove those blank area caused by alignment, this is implemented by retriving shift of each single channel image. But this method can't deal so well with the region that is originally black or white outside the image. Then I use a MSE(Mean Square Error) method to calculate each row and each column's error, and set up when three adjacent rows or columns all are smaller than certain threshold, it is the area should be cropped. The result shows as below:
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/crop/cathedral.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/emir.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/harvesters.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/icon.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/lady.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/self_portrait.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/three_generations.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/train.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/turkmen.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/crop/village.jpg" height="200px" alt="image_left">
                            </div>
                        </div>
                        <hr class="col-xs-12 mr-4">
                        <h3>Add Contrast</h3>
                        <p class="col-xs-12 mr-4">
                            The contrast method is pretty straight-forward, I just calculate the accumulative histogram of the image, and take 5% and 95% as 0 and 255 respectively, and stretch the color value in between so that the contrast of the main image increase.
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/contrast/cathedral.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/emir.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/harvesters.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/icon.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/lady.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/self_portrait.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/three_generations.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/train.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/turkmen.jpg" height="200px" alt="image_left">
                                <img src="./media/a1/contrast/village.jpg" height="200px" alt="image_left">
                            </div>
                        </div>
                        <hr class="col-xs-12 mr-4">
                        <h3>Other Dataset</h3>
                        <p class="col-xs-12 mr-4">
                            I find some other similar <a class="underline" href="http://lcweb2.loc.gov/master/pnp/prok/" target="_blank">dataset</a> that has pretty large tiff image to test the algorithm. The result shows as below
                        </p>
                        <div class="row mr-2">
                            <div class="text-center col-12">
                                <img src="./media/a1/outdata_crop/00001a.jpg" height="220px" alt="image_left">
                                <img src="./media/a1/outdata_crop/00002u.jpg" height="220px" alt="image_left">
                                <img src="./media/a1/outdata_crop/00004a.jpg" height="220px" alt="image_left">
                                <img src="./media/a1/outdata_crop/00005u.jpg" height="220px" alt="image_left">
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="tab-pane fade show active" id="a2" role="tabpanel" aria-labelledby="a2-tab">
                <div class="row">
                    <div class="col-12 my-5 mx-3">
                        <h2>Assignment #2</h2>
                        <hr class="col-xs-12 mr-4">
                        <h3>Introduction</h3>
                        <p class="col-xs-12 mr-4">
                            The Prokudin-Gorskii image collection from the Library of Congress is a series of glass plate negative photographs taken by Sergei Mikhailovich Prokudin-Gorskii. To view these photographs in color digitally, one must overlay the three images and display them in their respective RGB channels. However, due to the technology used to take these images, the three photos are not perfectly aligned. The goal of this project is to automatically align, clean up, and display a single color photograph from a glass plate negative.
                        </p>
                        <hr class="col-xs-12 mr-4">
                    </div>
                </div>
            </div>
            <div class="tab-pane fade" id="a3" role="tabpanel" aria-labelledby="a3-tab">
                <div class="row">
                    <div class="col-12 my-5 mx-3">
                        <h2>Assignment #3</h2>
                        <hr class="col-xs-12 mr-4">
                        <p class="col-xs-12 mr-4">Lorem ipsum dolor sit amet, no eum reque putent scripta. Eos esse vidit nonumy eu. Sit ut nominati prodesset, affert consul expetendis et cum. Sea cu animal cotidieque. Ei qui affert voluptua hendrerit, eripuit menandri pericula et per. Eam cu iusto possim vocent, veri mazim sensibus ea has, salutandi periculis his eu. Mei tractatos sententiae no.
                            Eu vim eirmod molestie electram, eam ad dicunt facilisi conclusionemque, at nostrud delectus incorrupte mea. Vel ea liber munere maluisset, cu habeo cotidieque vel, blandit indoctum ei vel. Sit invidunt erroribus ne. Ea postea possit persecuti qui, tota dicit discere ut usu. Mei te iudicabit repudiare. Legere tritani definitiones vix ei, mea ea eros singulis.
                            Qui ne posidonium definitionem, maluisset repudiare appellantur eam et, vim et vivendum facilisi delicatissimi. Ius ei choro dictas. Sit in atqui antiopam, ut his iuvaret oportere sapientem. Solet equidem recteque eum at, nam mundi perpetua te.
                            Eum te semper appareat omittantur. Labitur perpetua ea mea, nam ea impetus partiendo. Elitr perfecto adipisci ut eum, his vocibus tincidunt incorrupte et. Ad duo putant tractatos. Sint case qualisque vis cu, soluta percipitur eu eam, cum inermis definitionem cu. Ne summo democritum pri, et falli ludus eruditi nam.
                            Per assum mucius ex, no nec petentium delicatissimi, et pri hinc tacimates similique. Purto prima omnes vel ad, eu feugiat nostrum eum, ut has idque laoreet periculis. Ad vel officiis lucilius accusata, nonumy volutpat te qui. Noster indoctum mediocritatem ne cum.</p>
                    </div>
                </div>
            </div>
            <div class="tab-pane fade" id="a4" role="tabpanel" aria-labelledby="a4-tab">
                <div class="row">
                    <div class="col-12 my-5 mx-3">
                        <h2>Assignment #4</h2>
                        <hr class="col-xs-12 mr-4">
                        <p class="col-xs-12 mr-4">Lorem ipsum dolor sit amet, no eum reque putent scripta. Eos esse vidit nonumy eu. Sit ut nominati prodesset, affert consul expetendis et cum. Sea cu animal cotidieque. Ei qui affert voluptua hendrerit, eripuit menandri pericula et per. Eam cu iusto possim vocent, veri mazim sensibus ea has, salutandi periculis his eu. Mei tractatos sententiae no.
                            Eu vim eirmod molestie electram, eam ad dicunt facilisi conclusionemque, at nostrud delectus incorrupte mea. Vel ea liber munere maluisset, cu habeo cotidieque vel, blandit indoctum ei vel. Sit invidunt erroribus ne. Ea postea possit persecuti qui, tota dicit discere ut usu. Mei te iudicabit repudiare. Legere tritani definitiones vix ei, mea ea eros singulis.
                            Qui ne posidonium definitionem, maluisset repudiare appellantur eam et, vim et vivendum facilisi delicatissimi. Ius ei choro dictas. Sit in atqui antiopam, ut his iuvaret oportere sapientem. Solet equidem recteque eum at, nam mundi perpetua te.
                            Eum te semper appareat omittantur. Labitur perpetua ea mea, nam ea impetus partiendo. Elitr perfecto adipisci ut eum, his vocibus tincidunt incorrupte et. Ad duo putant tractatos. Sint case qualisque vis cu, soluta percipitur eu eam, cum inermis definitionem cu. Ne summo democritum pri, et falli ludus eruditi nam.
                            Per assum mucius ex, no nec petentium delicatissimi, et pri hinc tacimates similique. Purto prima omnes vel ad, eu feugiat nostrum eum, ut has idque laoreet periculis. Ad vel officiis lucilius accusata, nonumy volutpat te qui. Noster indoctum mediocritatem ne cum.</p>
                    </div>
                </div>
            </div>
            <div class="tab-pane fade" id="a5" role="tabpanel" aria-labelledby="a5-tab">
                <div class="row">
                    <div class="col-12 my-5 mx-3">
                        <h2>Assignment #5</h2>
                        <hr class="col-xs-12 mr-4">
                        <p class="col-xs-12 mr-4">Lorem ipsum dolor sit amet, no eum reque putent scripta. Eos esse vidit nonumy eu. Sit ut nominati prodesset, affert consul expetendis et cum. Sea cu animal cotidieque. Ei qui affert voluptua hendrerit, eripuit menandri pericula et per. Eam cu iusto possim vocent, veri mazim sensibus ea has, salutandi periculis his eu. Mei tractatos sententiae no.
                            Eu vim eirmod molestie electram, eam ad dicunt facilisi conclusionemque, at nostrud delectus incorrupte mea. Vel ea liber munere maluisset, cu habeo cotidieque vel, blandit indoctum ei vel. Sit invidunt erroribus ne. Ea postea possit persecuti qui, tota dicit discere ut usu. Mei te iudicabit repudiare. Legere tritani definitiones vix ei, mea ea eros singulis.
                            Qui ne posidonium definitionem, maluisset repudiare appellantur eam et, vim et vivendum facilisi delicatissimi. Ius ei choro dictas. Sit in atqui antiopam, ut his iuvaret oportere sapientem. Solet equidem recteque eum at, nam mundi perpetua te.
                            Eum te semper appareat omittantur. Labitur perpetua ea mea, nam ea impetus partiendo. Elitr perfecto adipisci ut eum, his vocibus tincidunt incorrupte et. Ad duo putant tractatos. Sint case qualisque vis cu, soluta percipitur eu eam, cum inermis definitionem cu. Ne summo democritum pri, et falli ludus eruditi nam.
                            Per assum mucius ex, no nec petentium delicatissimi, et pri hinc tacimates similique. Purto prima omnes vel ad, eu feugiat nostrum eum, ut has idque laoreet periculis. Ad vel officiis lucilius accusata, nonumy volutpat te qui. Noster indoctum mediocritatem ne cum.</p>
                    </div>
                </div>
            </div>
        </div>
        <!-- footer -->
        <div id="footer" class="text-center py-3">©2022 Copyright | <a href="http://caoyuchen.github.io" target="_blank">Joshua Cao</a> | yuchenca@andrew.cmu.edu</div>
    </div>
</body>

</html>
<!-- cloud effect -->
<script>
VANTA.CLOUDS2({
    el: "#cloud",
    mouseControls: true,
    touchControls: true,
    gyroControls: false,
    minHeight: 200.00,
    minWidth: 200.00,
    scale: 1.00,
    // skyColor: 0x6381b1,
    // cloudColor: 0x646493,
    speed: 1.50,
    texturePath: "./media/noise.png"
})
</script>
