{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8672423c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-21ef9330a379>, line 172)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-21ef9330a379>\"\u001b[1;36m, line \u001b[1;32m172\u001b[0m\n\u001b[1;33m    D_real_loss =\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# CMU 16-726 Learning-Based Image Synthesis / Spring 2022, Assignment 3\n",
    "#\n",
    "# The code base is based on the great work from CSC 321, U Toronto\n",
    "# https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip\n",
    "# This is the main training file for the first part of the assignment.\n",
    "#\n",
    "# Usage:\n",
    "# ======\n",
    "#    To train with the default hyperparamters (saves results to checkpoints_vanilla/ and samples_vanilla/):\n",
    "#       python vanilla_gan.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import imageio\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Numpy & Scipy imports\n",
    "import numpy as np\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "from data_loader import get_data_loader\n",
    "from models import DCGenerator, DCDiscriminator\n",
    "\n",
    "from diff_augment import DiffAugment\n",
    "policy = 'color,translation,cutout'\n",
    "\n",
    "\n",
    "SEED = 11\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def print_models(G, D):\n",
    "    \"\"\"Prints model information for the generators and discriminators.\n",
    "    \"\"\"\n",
    "    print(\"                    G                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(G)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    print(\"                    D                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(D)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "\n",
    "def create_model(opts):\n",
    "    \"\"\"Builds the generators and discriminators.\n",
    "    \"\"\"\n",
    "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.conv_dim)\n",
    "    D = DCDiscriminator(conv_dim=opts.conv_dim)\n",
    "\n",
    "    print_models(G, D)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        print('Models moved to GPU.')\n",
    "\n",
    "    return G, D\n",
    "\n",
    "\n",
    "def create_image_grid(array, ncols=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_images, channels, cell_h, cell_w = array.shape\n",
    "\n",
    "    if not ncols:\n",
    "        ncols = int(np.sqrt(num_images))\n",
    "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
    "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
    "    for i in range(0, nrows):\n",
    "        for j in range(0, ncols):\n",
    "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j].transpose(1, 2, 0)\n",
    "\n",
    "    if channels == 1:\n",
    "        result = result.squeeze()\n",
    "    return result\n",
    "\n",
    "\n",
    "def checkpoint(iteration, G, D, opts):\n",
    "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
    "    \"\"\"\n",
    "    G_path = os.path.join(opts.checkpoint_dir, 'G_iter%d.pkl' % iteration)\n",
    "    D_path = os.path.join(opts.checkpoint_dir, 'D_iter%d.pkl' % iteration)\n",
    "    torch.save(G.state_dict(), G_path)\n",
    "    torch.save(D.state_dict(), D_path)\n",
    "\n",
    "\n",
    "def save_samples(G, fixed_noise, iteration, opts):\n",
    "    generated_images = G(fixed_noise)\n",
    "    generated_images = utils.to_data(generated_images)\n",
    "\n",
    "    grid = create_image_grid(generated_images)\n",
    "\n",
    "    # merged = merge_images(X, fake_Y, opts)\n",
    "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
    "    imageio.imwrite(path, grid)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "\n",
    "def save_images(images, iteration, opts, name):\n",
    "    grid = create_image_grid(utils.to_data(images))\n",
    "\n",
    "    path = os.path.join(opts.sample_dir, '{:s}-{:06d}.png'.format(name, iteration))\n",
    "    imageio.imwrite(path, grid)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "\n",
    "def sample_noise(dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Variable of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "\n",
    "    Output:\n",
    "    - A PyTorch Variable of shape (batch_size, dim, 1, 1) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    return utils.to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "\n",
    "def training_loop(train_dataloader, opts):\n",
    "    \"\"\"Runs the training loop.\n",
    "        * Saves checkpoints every opts.checkpoint_every iterations\n",
    "        * Saves generated samples every opts.sample_every iterations\n",
    "    \"\"\"\n",
    "\n",
    "    # Create generators and discriminators\n",
    "    G, D = create_model(opts)\n",
    "\n",
    "    # Create optimizers for the generators and discriminators\n",
    "    g_optimizer = optim.Adam(G.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
    "    d_optimizer = optim.Adam(D.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
    "\n",
    "    # Generate fixed noise for sampling from the generator\n",
    "    fixed_noise = sample_noise(opts.noise_size)  # batch_size x noise_size x 1 x 1\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    total_train_iters = opts.num_epochs * len(train_dataloader)\n",
    "\n",
    "    for epoch in range(opts.num_epochs):\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "\n",
    "            real_images, labels = batch\n",
    "            real_images, labels = utils.to_var(real_images), utils.to_var(labels).long().squeeze()\n",
    "\n",
    "            ################################################\n",
    "            ###         TRAIN THE DISCRIMINATOR         ####\n",
    "            ################################################\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Compute the discriminator loss on real images\n",
    "            # D_real_loss = torch.mean((D(real_images) - 1)**2)\n",
    "            D_real_loss = \n",
    "\n",
    "            # 2. Sample noise\n",
    "            noise = \n",
    "\n",
    "            # 3. Generate fake images from the noise\n",
    "            fake_images = \n",
    "\n",
    "            # 4. Compute the discriminator loss on the fake images\n",
    "            # D_fake_loss = torch.mean((D(fake_images.detach())) ** 2)\n",
    "            D_fake_loss = \n",
    "\n",
    "            D_total_loss = \n",
    "\n",
    "            # update the discriminator D\n",
    "            d_optimizer.zero_grad()\n",
    "            D_total_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            ###########################################\n",
    "            ###          TRAIN THE GENERATOR        ###\n",
    "            ###########################################\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Sample noise\n",
    "            noise = \n",
    "\n",
    "            # 2. Generate fake images from the noise\n",
    "            fake_images = \n",
    "\n",
    "            # 3. Compute the generator loss\n",
    "            G_loss = \n",
    "\n",
    "            # update the generator G\n",
    "            g_optimizer.zero_grad()\n",
    "            G_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Print the log info\n",
    "            if iteration % opts.log_step == 0:\n",
    "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
    "                       iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
    "                logger.add_scalar('D/fake', D_fake_loss, iteration)\n",
    "                logger.add_scalar('D/real', D_real_loss, iteration)\n",
    "                logger.add_scalar('D/total', D_total_loss, iteration)\n",
    "                logger.add_scalar('G/total', G_loss, iteration)\n",
    "\n",
    "            # Save the generated samples\n",
    "            if iteration % opts.sample_every == 0:\n",
    "                save_samples(G, fixed_noise, iteration, opts)\n",
    "                save_images(real_images, iteration, opts, 'real')\n",
    "\n",
    "            # Save the model parameters\n",
    "            if iteration % opts.checkpoint_every == 0:\n",
    "                checkpoint(iteration, G, D, opts)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "\n",
    "def main(opts):\n",
    "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dataloader for the training images\n",
    "    dataloader = get_data_loader(opts.data, opts)\n",
    "\n",
    "    # Create checkpoint and sample directories\n",
    "    utils.create_dir(opts.checkpoint_dir)\n",
    "    utils.create_dir(opts.sample_dir)\n",
    "\n",
    "    training_loop(dataloader, opts)\n",
    "\n",
    "\n",
    "def create_parser():\n",
    "    \"\"\"Creates a parser for command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model hyper-parameters\n",
    "    parser.add_argument('--image_size', type=int, default=64, help='The side length N to convert images to NxN.')\n",
    "    parser.add_argument('--conv_dim', type=int, default=32)\n",
    "    parser.add_argument('--noise_size', type=int, default=100)\n",
    "\n",
    "    # Training hyper-parameters\n",
    "    parser.add_argument('--num_epochs', type=int, default=500)\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='The number of images in a batch.')\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')\n",
    "    parser.add_argument('--lr', type=float, default=0.0002, help='The learning rate (default 0.0002)')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5)\n",
    "    parser.add_argument('--beta2', type=float, default=0.999)\n",
    "\n",
    "    # Data sources\n",
    "    parser.add_argument('--data', type=str, default='cat/grumpifyBprocessed', help='The folder of the training dataset.')\n",
    "    parser.add_argument('--data_preprocess', type=str, default='deluxe', help='data preprocess scheme [basic|deluxe]')\n",
    "    parser.add_argument('--ext', type=str, default='*.png', help='Choose the file type of images to generate.')\n",
    "\n",
    "    # Directories and checkpoint/sample iterations\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_vanilla')\n",
    "    parser.add_argument('--sample_dir', type=str, default='./vanilla')\n",
    "    parser.add_argument('--log_step', type=int , default=10)\n",
    "    parser.add_argument('--sample_every', type=int , default=200)\n",
    "    parser.add_argument('--checkpoint_every', type=int , default=400)\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = create_parser()\n",
    "    opts = parser.parse_args()\n",
    "\n",
    "    batch_size = opts.batch_size\n",
    "    opts.sample_dir = os.path.join('output/', opts.sample_dir,\n",
    "                                   '%s_%s' % (os.path.basename(opts.data), opts.data_preprocess))\n",
    "    if opts.use_diffaug:\n",
    "        opts.sample_dir += '_diffaug'\n",
    "\n",
    "    if os.path.exists(opts.sample_dir):\n",
    "        cmd = 'rm %s/*' % opts.sample_dir\n",
    "        os.system(cmd)\n",
    "    logger = SummaryWriter(opts.sample_dir)\n",
    "    print(opts)\n",
    "    main(opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMU 16-726 Learning-Based Image Synthesis / Spring 2022, Assignment 3\n",
    "#\n",
    "# The code base is based on the great work from CSC 321, U Toronto\n",
    "# https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip\n",
    "# This is the main training file for the second part of the assignment.\n",
    "#\n",
    "# Usage:\n",
    "# ======\n",
    "#    To train with the default hyperparamters (saves results to samples_cyclegan/):\n",
    "#       python cycle_gan.py\n",
    "#\n",
    "#    To train with cycle consistency loss (saves results to samples_cyclegan_cycle/):\n",
    "#       python cycle_gan.py --use_cycle_consistency_loss\n",
    "#\n",
    "#\n",
    "#    For optional experimentation:\n",
    "#    -----------------------------\n",
    "#    If you have a powerful computer (ideally with a GPU), then you can obtain better results by\n",
    "#    increasing the number of filters used in the generator and/or discriminator, as follows:\n",
    "#      python cycle_gan.py --g_conv_dim=64 --d_conv_dim=64\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import imageio\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Numpy & Scipy imports\n",
    "import numpy as np\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "from data_loader import get_data_loader\n",
    "from models import CycleGenerator, DCDiscriminator, PatchDiscriminator\n",
    "\n",
    "from diff_augment import DiffAugment\n",
    "policy = 'color,translation,cutout' # If your dataset is as small as ours (e.g.,\n",
    "\n",
    "SEED = 11\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def print_models(G_XtoY, G_YtoX, D_X, D_Y):\n",
    "    \"\"\"Prints model information for the generators and discriminators.\n",
    "    \"\"\"\n",
    "    print(\"                 G_XtoY                \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(G_XtoY)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    print(\"                 G_YtoX                \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(G_YtoX)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    print(\"                  D_X                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(D_X)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    print(\"                  D_Y                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(D_Y)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "\n",
    "def create_model(opts):\n",
    "    \"\"\"Builds the generators and discriminators.\n",
    "    \"\"\"\n",
    "    model_dict = {'cycle': CycleGenerator}\n",
    "    G_XtoY = model_dict[opts.gen](conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights, norm=opts.norm)\n",
    "    G_YtoX = model_dict[opts.gen](conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights, norm=opts.norm)\n",
    "\n",
    "    model_dict = {'dc': DCDiscriminator, 'patch': PatchDiscriminator}\n",
    "    D_X = model_dict[opts.disc](conv_dim=opts.d_conv_dim, norm=opts.norm)\n",
    "    D_Y = model_dict[opts.disc](conv_dim=opts.d_conv_dim, norm=opts.norm)\n",
    "    print_models(G_XtoY, G_YtoX, D_X, D_Y)\n",
    "\n",
    "    # TODO: B&W add your own initialization here\n",
    "    # \n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        G_XtoY.cuda()\n",
    "        G_YtoX.cuda()\n",
    "        D_X.cuda()\n",
    "        D_Y.cuda()\n",
    "        print('Models moved to GPU.')\n",
    "\n",
    "    return G_XtoY, G_YtoX, D_X, D_Y\n",
    "\n",
    "\n",
    "def checkpoint(iteration, G_XtoY, G_YtoX, D_X, D_Y, opts):\n",
    "    \"\"\"Saves the parameters of both generators G_YtoX, G_XtoY and discriminators D_X, D_Y.\n",
    "    \"\"\"\n",
    "    G_XtoY_path = os.path.join(opts.checkpoint_dir, 'G_XtoY_iter%d.pkl' % iteration)\n",
    "    G_YtoX_path = os.path.join(opts.checkpoint_dir, 'G_YtoX_iter%d.pkl' % iteration)\n",
    "    D_X_path = os.path.join(opts.checkpoint_dir, 'D_X_iter%d.pkl' % iteration)\n",
    "    D_Y_path = os.path.join(opts.checkpoint_dir, 'D_Y_iter%d.pkl' % iteration)\n",
    "    torch.save(G_XtoY.state_dict(), G_XtoY_path)\n",
    "    torch.save(G_YtoX.state_dict(), G_YtoX_path)\n",
    "    torch.save(D_X.state_dict(), D_X_path)\n",
    "    torch.save(D_Y.state_dict(), D_Y_path)\n",
    "\n",
    "\n",
    "def merge_images(sources, targets, opts, k=10):\n",
    "    \"\"\"Creates a grid consisting of pairs of columns, where the first column in\n",
    "    each pair contains images source images and the second column in each pair\n",
    "    contains images generated by the CycleGAN from the corresponding images in\n",
    "    the first column.\n",
    "    \"\"\"\n",
    "    _, _, h, w = sources.shape\n",
    "    row = int(np.sqrt(opts.batch_size))\n",
    "    merged = np.zeros([3, row*h, row*w*2])\n",
    "    for idx, (s, t) in enumerate(zip(sources, targets)):\n",
    "        i = idx // row\n",
    "        j = idx % row\n",
    "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
    "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
    "    return merged.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "def save_samples(iteration, fixed_Y, fixed_X, G_YtoX, G_XtoY, opts):\n",
    "    \"\"\"Saves samples from both generators X->Y and Y->X.\n",
    "    \"\"\"\n",
    "    fake_X = G_YtoX(fixed_Y)\n",
    "    fake_Y = G_XtoY(fixed_X)\n",
    "\n",
    "    X, fake_X = utils.to_data(fixed_X), utils.to_data(fake_X)\n",
    "    Y, fake_Y = utils.to_data(fixed_Y), utils.to_data(fake_Y)\n",
    "\n",
    "    merged = merge_images(X, fake_Y, opts)\n",
    "    path = os.path.join(opts.sample_dir, 'sample-{:06d}-X-Y.png'.format(iteration))\n",
    "    imageio.imwrite(path, merged)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "    merged = merge_images(Y, fake_X, opts)\n",
    "    path = os.path.join(opts.sample_dir, 'sample-{:06d}-Y-X.png'.format(iteration))\n",
    "    imageio.imwrite(path, merged)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "\n",
    "def training_loop(dataloader_X, dataloader_Y, opts):\n",
    "    \"\"\"Runs the training loop.\n",
    "        * Saves checkpoint every opts.checkpoint_every iterations\n",
    "        * Saves generated samples every opts.sample_every iterations\n",
    "    \"\"\"\n",
    "\n",
    "    # Create generators and discriminators\n",
    "    G_XtoY, G_YtoX, D_X, D_Y = create_model(opts)\n",
    "\n",
    "    g_params = list(G_XtoY.parameters()) + list(G_YtoX.parameters())  # Get generator parameters\n",
    "    d_params = list(D_X.parameters()) + list(D_Y.parameters())  # Get discriminator parameters\n",
    "\n",
    "    # Create optimizers for the generators and discriminators\n",
    "    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])\n",
    "    d_optimizer = optim.Adam(d_params, opts.lr, [opts.beta1, opts.beta2])\n",
    "\n",
    "    iter_X = iter(dataloader_X)\n",
    "    iter_Y = iter(dataloader_Y)\n",
    "\n",
    "\n",
    "    # Get some fixed data from domains X and Y for sampling. These are images that are held\n",
    "    # constant throughout training, that allow us to inspect the model's performance.\n",
    "    fixed_X = utils.to_var(iter_X.next()[0])\n",
    "    fixed_Y = utils.to_var(iter_Y.next()[0])\n",
    "\n",
    "    iter_per_epoch = min(len(iter_X), len(iter_Y))\n",
    "\n",
    "    for iteration in range(1, opts.train_iters+1):\n",
    "\n",
    "        # Reset data_iter for each epoch\n",
    "        if iteration % iter_per_epoch == 0:\n",
    "            iter_X = iter(dataloader_X)\n",
    "            iter_Y = iter(dataloader_Y)\n",
    "\n",
    "        images_X, labels_X = iter_X.next()\n",
    "        images_X, labels_X = utils.to_var(images_X), utils.to_var(labels_X).long().squeeze()\n",
    "\n",
    "        images_Y, labels_Y = iter_Y.next()\n",
    "        images_Y, labels_Y = utils.to_var(images_Y), utils.to_var(labels_Y).long().squeeze()\n",
    "\n",
    "\n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATORS\n",
    "        # ============================================\n",
    "\n",
    "        #########################################\n",
    "        ##             FILL THIS IN            ##\n",
    "        #########################################\n",
    "\n",
    "        # 1. Compute the discriminator losses on real images\n",
    "        D_X_loss = \n",
    "        D_Y_loss = \n",
    "\n",
    "        d_real_loss = D_X_loss + D_Y_loss\n",
    "\n",
    "        # 2. Generate fake images that look like domain X based on real images in domain Y\n",
    "        fake_X = \n",
    "\n",
    "        # 3. Compute the loss for D_X\n",
    "        D_X_loss = \n",
    "\n",
    "        # 4. Generate fake images that look like domain Y based on real images in domain X\n",
    "        fake_Y = \n",
    "\n",
    "        # 5. Compute the loss for D_Y\n",
    "        D_Y_loss = \n",
    "\n",
    "        d_fake_loss = D_X_loss + D_Y_loss\n",
    "\n",
    "        # sum up the losses and update D_X and D_Y\n",
    "        d_optimizer.zero_grad()\n",
    "        d_total_loss = d_real_loss + d_fake_loss\n",
    "        d_total_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # plot the losses in tensorboard\n",
    "        logger.add_scalar('D/XY/real', D_X_loss, iteration)\n",
    "        logger.add_scalar('D/YX/real', D_Y_loss, iteration)\n",
    "        logger.add_scalar('D/XY/fake', D_X_loss, iteration)\n",
    "        logger.add_scalar('D/YX/fake', D_Y_loss, iteration)\n",
    "\n",
    "\n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATORS\n",
    "        # =========================================\n",
    "\n",
    "\n",
    "        #########################################\n",
    "        ##    FILL THIS IN: Y--X-->Y CYCLE     ##\n",
    "        #########################################\n",
    "\n",
    "        # 1. Generate fake images that look like domain X based on real images in domain Y\n",
    "        fake_X = \n",
    "\n",
    "        # 2. Compute the generator loss based on domain X\n",
    "        g_loss = \n",
    "        logger.add_scalar('G/XY/fake', g_loss, iteration)\n",
    "\n",
    "        if opts.use_cycle_consistency_loss:\n",
    "            # 3. Compute the cycle consistency loss (the reconstruction loss)\n",
    "            cycle_consistency_loss = \n",
    "\n",
    "            g_loss += opts.lambda_cycle * cycle_consistency_loss\n",
    "            logger.add_scalar('G/XY/cycle', opts.lambda_cycle * cycle_consistency_loss, iteration)\n",
    "\n",
    "        #########################################\n",
    "        ##    FILL THIS IN: X--Y-->X CYCLE     ##\n",
    "        #########################################\n",
    "\n",
    "        # 1. Generate fake images that look like domain Y based on real images in domain X\n",
    "        fake_Y = \n",
    "\n",
    "        # 2. Compute the generator loss based on domain Y\n",
    "        g_loss += \n",
    "        logger.add_scalar('G/YX/fake', g_loss, iteration)\n",
    "\n",
    "        if opts.use_cycle_consistency_loss:\n",
    "            # 3. Compute the cycle consistency loss (the reconstruction loss)\n",
    "            cycle_consistency_loss = \n",
    "\n",
    "            g_loss += opts.lambda_cycle * cycle_consistency_loss\n",
    "            logger.add_scalar('G/YX/cycle', cycle_consistency_loss, iteration)\n",
    "\n",
    "        # backprop the aggregated g losses and update G_XtoY and G_YtoX\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print the log info\n",
    "        if iteration % opts.log_step == 0:\n",
    "            print('Iteration [{:5d}/{:5d}] | d_real_loss: {:6.4f} | d_Y_loss: {:6.4f} | d_X_loss: {:6.4f} | '\n",
    "                  'd_fake_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    iteration, opts.train_iters, d_real_loss.item(), D_Y_loss.item(),\n",
    "                    D_X_loss.item(), d_fake_loss.item(), g_loss.item()))\n",
    "\n",
    "        # Save the generated samples\n",
    "        if iteration % opts.sample_every == 0:\n",
    "            save_samples(iteration, fixed_Y, fixed_X, G_YtoX, G_XtoY, opts)\n",
    "\n",
    "        # Save the model parameters\n",
    "        if iteration % opts.checkpoint_every == 0:\n",
    "            checkpoint(iteration, G_XtoY, G_YtoX, D_X, D_Y, opts)\n",
    "\n",
    "\n",
    "def main(opts):\n",
    "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create  dataloaders for images from the two domains X and Y\n",
    "    dataloader_X= get_data_loader(opts.X, opts=opts)\n",
    "    dataloader_Y = get_data_loader(opts.Y, opts=opts)\n",
    "\n",
    "    # Create checkpoint and sample directories\n",
    "    utils.create_dir(opts.checkpoint_dir)\n",
    "    utils.create_dir(opts.sample_dir)\n",
    "\n",
    "    # Start training\n",
    "    training_loop(dataloader_X, dataloader_Y, opts)\n",
    "\n",
    "\n",
    "def print_opts(opts):\n",
    "    \"\"\"Prints the values of all command-line arguments.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Opts'.center(80))\n",
    "    print('-' * 80)\n",
    "    for key in opts.__dict__:\n",
    "        if opts.__dict__[key]:\n",
    "            print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
    "    print('=' * 80)\n",
    "\n",
    "\n",
    "def create_parser():\n",
    "    \"\"\"Creates a parser for command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model hyper-parameters\n",
    "    parser.add_argument('--image_size', type=int, default=64, help='The side length N to convert images to NxN.')\n",
    "    parser.add_argument('--disc', type=str, default='dc', help='Choose which discriminator to use. choices:[dc|patch]')\n",
    "    parser.add_argument('--gen', type=str, default='cycle')\n",
    "    parser.add_argument('--g_conv_dim', type=int, default=32)\n",
    "    parser.add_argument('--d_conv_dim', type=int, default=32)\n",
    "    parser.add_argument('--norm', type=str, default='instance')\n",
    "    parser.add_argument('--use_cycle_consistency_loss', action='store_true', default=False, help='Choose whether to include the cycle consistency term in the loss.')\n",
    "    parser.add_argument('--init_zero_weights', action='store_true', default=False, help='Choose whether to initialize the generator conv weights to 0 (implements the identity function).')\n",
    "    parser.add_argument('--init_type', type=str, default='naive')\n",
    "\n",
    "    # Training hyper-parameters\n",
    "    parser.add_argument('--train_iters', type=int, default=10000, help='The number of training iterations to run (you can Ctrl-C out earlier if you want).')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='The number of images in a batch.')\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')\n",
    "    parser.add_argument('--lr', type=float, default=0.0003, help='The learning rate (default 0.0003)')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5)\n",
    "    parser.add_argument('--beta2', type=float, default=0.999)\n",
    "    parser.add_argument('--lambda_cycle', type=float, default=10)\n",
    "\n",
    "    # Data sources\n",
    "    parser.add_argument('--X', type=str, default='cat/grumpifyAprocessed', help='Choose the type of images for domain X.')\n",
    "    parser.add_argument('--Y', type=str, default='cat/grumpifyBprocessed', help='Choose the type of images for domain Y.')\n",
    "    parser.add_argument('--ext', type=str, default='*.png', help='Choose the type of images for domain Y.')\n",
    "    parser.add_argument('--data_preprocess', type=str, default='deluxe', help='data preprocess scheme [basic|deluxe]')\n",
    "\n",
    "    # Saving directories and checkpoint/sample iterations\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints_cyclegan')\n",
    "    parser.add_argument('--sample_dir', type=str, default='cyclegan')\n",
    "    parser.add_argument('--log_step', type=int , default=10)\n",
    "    parser.add_argument('--sample_every', type=int , default=100)\n",
    "    parser.add_argument('--checkpoint_every', type=int , default=800)\n",
    "\n",
    "    parser.add_argument('--gpu', type=str, default='0')\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = create_parser()\n",
    "    opts = parser.parse_args()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = opts.gpu\n",
    "    opts.sample_dir = os.path.join('output/', opts.sample_dir,\n",
    "                                   '%s_%g' % (opts.X.split('/')[0], opts.lambda_cycle))\n",
    "    opts.sample_dir += '%s_%s_%s_%s_%s' % (opts.data_preprocess, opts.norm, opts.disc, opts.gen, opts.init_type)\n",
    "    if opts.use_cycle_consistency_loss:\n",
    "        opts.sample_dir += '_cycle'\n",
    "    if opts.use_diffaug:\n",
    "        opts.sample_dir += '_diffaug'\n",
    "\n",
    "    if os.path.exists(opts.sample_dir):\n",
    "        cmd = 'rm %s/*' % opts.sample_dir\n",
    "        os.system(cmd)\n",
    "\n",
    "    logger = SummaryWriter(opts.sample_dir)\n",
    "\n",
    "    print_opts(opts)\n",
    "    main(opts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
