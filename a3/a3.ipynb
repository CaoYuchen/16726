{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMU 16-726 Learning-Based Image Synthesis / Spring 2022, Assignment 3\n",
    "#\n",
    "# The code base is based on the great work from CSC 321, U Toronto\n",
    "# https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip\n",
    "# This is the main training file for the first part of the assignment.\n",
    "#\n",
    "# Usage:\n",
    "# ======\n",
    "#    To train with the default hyperparamters (saves results to checkpoints_vanilla/ and samples_vanilla/):\n",
    "#       python vanilla_gan.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import imageio\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Numpy & Scipy imports\n",
    "import numpy as np\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "from data_loader import get_data_loader\n",
    "from models import DCGenerator, DCDiscriminator\n",
    "\n",
    "from diff_augment import DiffAugment\n",
    "policy = 'color,translation,cutout'\n",
    "\n",
    "\n",
    "SEED = 11\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def print_models(G, D):\n",
    "    \"\"\"Prints model information for the generators and discriminators.\n",
    "    \"\"\"\n",
    "    print(\"                    G                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(G)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    print(\"                    D                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(D)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "\n",
    "def create_model(opts):\n",
    "    \"\"\"Builds the generators and discriminators.\n",
    "    \"\"\"\n",
    "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.conv_dim)\n",
    "    D = DCDiscriminator(conv_dim=opts.conv_dim)\n",
    "\n",
    "    print_models(G, D)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        print('Models moved to GPU.')\n",
    "\n",
    "    return G, D\n",
    "\n",
    "\n",
    "def create_image_grid(array, ncols=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_images, channels, cell_h, cell_w = array.shape\n",
    "\n",
    "    if not ncols:\n",
    "        ncols = int(np.sqrt(num_images))\n",
    "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
    "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
    "    for i in range(0, nrows):\n",
    "        for j in range(0, ncols):\n",
    "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j].transpose(1, 2, 0)\n",
    "\n",
    "    if channels == 1:\n",
    "        result = result.squeeze()\n",
    "    return result\n",
    "\n",
    "\n",
    "def checkpoint(iteration, G, D, opts):\n",
    "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
    "    \"\"\"\n",
    "    G_path = os.path.join(opts.checkpoint_dir, 'G_iter%d.pkl' % iteration)\n",
    "    D_path = os.path.join(opts.checkpoint_dir, 'D_iter%d.pkl' % iteration)\n",
    "    torch.save(G.state_dict(), G_path)\n",
    "    torch.save(D.state_dict(), D_path)\n",
    "\n",
    "\n",
    "def save_samples(G, fixed_noise, iteration, opts):\n",
    "    generated_images = G(fixed_noise)\n",
    "    generated_images = utils.to_data(generated_images)\n",
    "\n",
    "    grid = create_image_grid(generated_images)\n",
    "\n",
    "    # merged = merge_images(X, fake_Y, opts)\n",
    "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
    "    imageio.imwrite(path, grid)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "\n",
    "def save_images(images, iteration, opts, name):\n",
    "    grid = create_image_grid(utils.to_data(images))\n",
    "\n",
    "    path = os.path.join(opts.sample_dir, '{:s}-{:06d}.png'.format(name, iteration))\n",
    "    imageio.imwrite(path, grid)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "\n",
    "def sample_noise(dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Variable of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "\n",
    "    Output:\n",
    "    - A PyTorch Variable of shape (batch_size, dim, 1, 1) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    return utils.to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "\n",
    "def training_loop(train_dataloader, opts):\n",
    "    \"\"\"Runs the training loop.\n",
    "        * Saves checkpoints every opts.checkpoint_every iterations\n",
    "        * Saves generated samples every opts.sample_every iterations\n",
    "    \"\"\"\n",
    "\n",
    "    # Create generators and discriminators\n",
    "    G, D = create_model(opts)\n",
    "\n",
    "    # Create optimizers for the generators and discriminators\n",
    "    g_optimizer = optim.Adam(G.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
    "    d_optimizer = optim.Adam(D.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
    "\n",
    "    # Generate fixed noise for sampling from the generator\n",
    "    fixed_noise = sample_noise(opts.noise_size)  # batch_size x noise_size x 1 x 1\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    total_train_iters = opts.num_epochs * len(train_dataloader)\n",
    "\n",
    "    for epoch in range(opts.num_epochs):\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "\n",
    "            real_images, labels = batch\n",
    "            real_images, labels = utils.to_var(real_images), utils.to_var(labels).long().squeeze()\n",
    "\n",
    "            ################################################\n",
    "            ###         TRAIN THE DISCRIMINATOR         ####\n",
    "            ################################################\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Compute the discriminator loss on real images\n",
    "            # D_real_loss = torch.mean((D(real_images) - 1)**2)\n",
    "            D_real_loss = \n",
    "\n",
    "            # 2. Sample noise\n",
    "            noise = \n",
    "\n",
    "            # 3. Generate fake images from the noise\n",
    "            fake_images = \n",
    "\n",
    "            # 4. Compute the discriminator loss on the fake images\n",
    "            # D_fake_loss = torch.mean((D(fake_images.detach())) ** 2)\n",
    "            D_fake_loss = \n",
    "\n",
    "            D_total_loss = \n",
    "\n",
    "            # update the discriminator D\n",
    "            d_optimizer.zero_grad()\n",
    "            D_total_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            ###########################################\n",
    "            ###          TRAIN THE GENERATOR        ###\n",
    "            ###########################################\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Sample noise\n",
    "            noise = \n",
    "\n",
    "            # 2. Generate fake images from the noise\n",
    "            fake_images = \n",
    "\n",
    "            # 3. Compute the generator loss\n",
    "            G_loss = \n",
    "\n",
    "            # update the generator G\n",
    "            g_optimizer.zero_grad()\n",
    "            G_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Print the log info\n",
    "            if iteration % opts.log_step == 0:\n",
    "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
    "                       iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
    "                logger.add_scalar('D/fake', D_fake_loss, iteration)\n",
    "                logger.add_scalar('D/real', D_real_loss, iteration)\n",
    "                logger.add_scalar('D/total', D_total_loss, iteration)\n",
    "                logger.add_scalar('G/total', G_loss, iteration)\n",
    "\n",
    "            # Save the generated samples\n",
    "            if iteration % opts.sample_every == 0:\n",
    "                save_samples(G, fixed_noise, iteration, opts)\n",
    "                save_images(real_images, iteration, opts, 'real')\n",
    "\n",
    "            # Save the model parameters\n",
    "            if iteration % opts.checkpoint_every == 0:\n",
    "                checkpoint(iteration, G, D, opts)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "\n",
    "def main(opts):\n",
    "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dataloader for the training images\n",
    "    dataloader = get_data_loader(opts.data, opts)\n",
    "\n",
    "    # Create checkpoint and sample directories\n",
    "    utils.create_dir(opts.checkpoint_dir)\n",
    "    utils.create_dir(opts.sample_dir)\n",
    "\n",
    "    training_loop(dataloader, opts)\n",
    "\n",
    "\n",
    "def create_parser():\n",
    "    \"\"\"Creates a parser for command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model hyper-parameters\n",
    "    parser.add_argument('--image_size', type=int, default=64, help='The side length N to convert images to NxN.')\n",
    "    parser.add_argument('--conv_dim', type=int, default=32)\n",
    "    parser.add_argument('--noise_size', type=int, default=100)\n",
    "\n",
    "    # Training hyper-parameters\n",
    "    parser.add_argument('--num_epochs', type=int, default=500)\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='The number of images in a batch.')\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')\n",
    "    parser.add_argument('--lr', type=float, default=0.0002, help='The learning rate (default 0.0002)')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5)\n",
    "    parser.add_argument('--beta2', type=float, default=0.999)\n",
    "\n",
    "    # Data sources\n",
    "    parser.add_argument('--data', type=str, default='cat/grumpifyBprocessed', help='The folder of the training dataset.')\n",
    "    parser.add_argument('--data_preprocess', type=str, default='deluxe', help='data preprocess scheme [basic|deluxe]')\n",
    "    parser.add_argument('--ext', type=str, default='*.png', help='Choose the file type of images to generate.')\n",
    "\n",
    "    # Directories and checkpoint/sample iterations\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_vanilla')\n",
    "    parser.add_argument('--sample_dir', type=str, default='./vanilla')\n",
    "    parser.add_argument('--log_step', type=int , default=10)\n",
    "    parser.add_argument('--sample_every', type=int , default=200)\n",
    "    parser.add_argument('--checkpoint_every', type=int , default=400)\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = create_parser()\n",
    "    opts = parser.parse_args()\n",
    "\n",
    "    batch_size = opts.batch_size\n",
    "    opts.sample_dir = os.path.join('output/', opts.sample_dir,\n",
    "                                   '%s_%s' % (os.path.basename(opts.data), opts.data_preprocess))\n",
    "    if opts.use_diffaug:\n",
    "        opts.sample_dir += '_diffaug'\n",
    "\n",
    "    if os.path.exists(opts.sample_dir):\n",
    "        cmd = 'rm %s/*' % opts.sample_dir\n",
    "        os.system(cmd)\n",
    "    logger = SummaryWriter(opts.sample_dir)\n",
    "    print(opts)\n",
    "    main(opts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
